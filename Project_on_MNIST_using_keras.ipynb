{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_on_MNIST_using_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTJmsXnXQKbG"
      },
      "source": [
        "## Keras -- MLPs on MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UILABPAQKbH"
      },
      "source": [
        "# if you keras is not using tensorflow as backend set \"KERAS_BACKEND=tensorflow\" use this command\n",
        "# import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist \n",
        "import seaborn as sns\n",
        "from keras.initializers import RandomNormal"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOO-TM_7QKbM"
      },
      "source": [
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKmYKnibQKbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "739ad900-3a49-40cf-a443-82f1fa61adec"
      },
      "source": [
        "# the data, shuffled and split between train and test sets \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCwnZae-QKbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f105c31a-6331-4823-d9da-d19f82adffd3"
      },
      "source": [
        "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d, %d)\"%(X_train.shape[1], X_train.shape[2]))\n",
        "print(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d, %d)\"%(X_test.shape[1], X_test.shape[2]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples : 60000 and each image is of shape (28, 28)\n",
            "Number of training examples : 10000 and each image is of shape (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlotuCmoQKbW"
      },
      "source": [
        "# if you observe the input shape its 2 dimensional vector\n",
        "# for each image we have a (28*28) vector\n",
        "# we will convert the (28*28) vector into single dimensional vector of 1 * 784 \n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]) \n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]) "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JvpNJy4QKbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ece638-38e4-472a-d9bb-3b9c78dae29a"
      },
      "source": [
        "# after converting the input images from 3d to 2d vectors\n",
        "\n",
        "print(\"Number of training examples :\", X_train.shape[0], \"and each image is of shape (%d)\"%(X_train.shape[1]))\n",
        "print(\"Number of training examples :\", X_test.shape[0], \"and each image is of shape (%d)\"%(X_test.shape[1]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples : 60000 and each image is of shape (784)\n",
            "Number of training examples : 10000 and each image is of shape (784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfohtdKPQKbd"
      },
      "source": [
        "# if we observe the above matrix each cell is having a value between 0-255\n",
        "# before we move to apply machine learning algorithms lets try to normalize the data\n",
        "# X => (X - Xmin)/(Xmax-Xmin) = X/255\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ruu-vXzQKbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395e8ec4-3a30-4f02-961e-8081c39b0e51"
      },
      "source": [
        "# here we are having a class number for each image\n",
        "print(\"Class label of first image :\", y_train[0])\n",
        "\n",
        "# lets convert this into a 10 dimensional vector\n",
        "# ex: consider an image is 5 convert it into 5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "# this conversion needed for MLPs \n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 10) \n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(\"After converting the output into a vector : \",Y_train[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label of first image : 5\n",
            "After converting the output into a vector :  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0pWB6UyQKbk"
      },
      "source": [
        "<h2>  Softmax classifier  </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLAGMubCQKbm"
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Activation \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0s7jzhVQKbn"
      },
      "source": [
        "# some model parameters\n",
        "\n",
        "output_dim = 10\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "batch_size = 128 \n",
        "nb_epoch = 20"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdQg5wGDQKbr"
      },
      "source": [
        "# start building a model\n",
        "model = Sequential()\n",
        "model.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVA11VpmQKbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4059a8bc-9fed-4ecf-bb56-0c1cd2c24534"
      },
      "source": [
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train, steps_per_epoch=500, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test)) \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 7s 5ms/step - loss: 1.2543 - accuracy: 0.7099 - val_loss: 0.7824 - val_accuracy: 0.8406\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.6945 - accuracy: 0.8451 - val_loss: 0.5886 - val_accuracy: 0.8682\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.5717 - accuracy: 0.8625 - val_loss: 0.5112 - val_accuracy: 0.8783\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.5130 - accuracy: 0.8719 - val_loss: 0.4682 - val_accuracy: 0.8843\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4772 - accuracy: 0.8772 - val_loss: 0.4398 - val_accuracy: 0.8899\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4526 - accuracy: 0.8813 - val_loss: 0.4195 - val_accuracy: 0.8932\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4343 - accuracy: 0.8849 - val_loss: 0.4044 - val_accuracy: 0.8953\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4201 - accuracy: 0.8879 - val_loss: 0.3925 - val_accuracy: 0.8977\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4086 - accuracy: 0.8903 - val_loss: 0.3825 - val_accuracy: 0.8991\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3990 - accuracy: 0.8925 - val_loss: 0.3742 - val_accuracy: 0.9008\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3908 - accuracy: 0.8945 - val_loss: 0.3673 - val_accuracy: 0.9023\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3840 - accuracy: 0.8960 - val_loss: 0.3612 - val_accuracy: 0.9035\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3778 - accuracy: 0.8977 - val_loss: 0.3560 - val_accuracy: 0.9043\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3724 - accuracy: 0.8990 - val_loss: 0.3512 - val_accuracy: 0.9054\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3675 - accuracy: 0.9001 - val_loss: 0.3471 - val_accuracy: 0.9058\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3632 - accuracy: 0.9007 - val_loss: 0.3433 - val_accuracy: 0.9076\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3593 - accuracy: 0.9016 - val_loss: 0.3398 - val_accuracy: 0.9075\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3556 - accuracy: 0.9023 - val_loss: 0.3368 - val_accuracy: 0.9085\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3524 - accuracy: 0.9031 - val_loss: 0.3339 - val_accuracy: 0.9092\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3493 - accuracy: 0.9034 - val_loss: 0.3315 - val_accuracy: 0.9099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNpwTMHcQKbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1080972-393a-43d9-b3b8-8064b51862a2"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.33147910237312317\n",
            "Test accuracy: 0.9099000096321106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh4VWYrHQKbz"
      },
      "source": [
        " <h3>  MLP + Sigmoid activation + SGDOptimizer </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rzbngqHQKbz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7017be6a-ebb9-4fed-b393-c80ba61a2168"
      },
      "source": [
        "# Multilayer perceptron\n",
        "\n",
        "model_sigmoid = Sequential()\n",
        "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
        "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
        "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "model_sigmoid.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 468,874\n",
            "Trainable params: 468,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48vVImSpQKb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1866514b-5959-4206-c75e-97f7e84f2659"
      },
      "source": [
        "model_sigmoid.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 2.2649 - accuracy: 0.2374 - val_loss: 2.2168 - val_accuracy: 0.3791\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 2.1713 - accuracy: 0.4509 - val_loss: 2.1151 - val_accuracy: 0.4902\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 2.0519 - accuracy: 0.5825 - val_loss: 1.9700 - val_accuracy: 0.6225\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.8829 - accuracy: 0.6428 - val_loss: 1.7709 - val_accuracy: 0.7025\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.6680 - accuracy: 0.6871 - val_loss: 1.5397 - val_accuracy: 0.7210\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.4397 - accuracy: 0.7272 - val_loss: 1.3169 - val_accuracy: 0.7731\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 1.2349 - accuracy: 0.7616 - val_loss: 1.1301 - val_accuracy: 0.7737\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.0692 - accuracy: 0.7838 - val_loss: 0.9840 - val_accuracy: 0.8039\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.9409 - accuracy: 0.8020 - val_loss: 0.8712 - val_accuracy: 0.8167\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.8419 - accuracy: 0.8164 - val_loss: 0.7850 - val_accuracy: 0.8263\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.7648 - accuracy: 0.8275 - val_loss: 0.7170 - val_accuracy: 0.8376\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.7039 - accuracy: 0.8361 - val_loss: 0.6619 - val_accuracy: 0.8462\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.6548 - accuracy: 0.8438 - val_loss: 0.6186 - val_accuracy: 0.8537\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.6150 - accuracy: 0.8500 - val_loss: 0.5818 - val_accuracy: 0.8596\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5819 - accuracy: 0.8564 - val_loss: 0.5518 - val_accuracy: 0.8648\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5543 - accuracy: 0.8605 - val_loss: 0.5266 - val_accuracy: 0.8673\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.5306 - accuracy: 0.8651 - val_loss: 0.5046 - val_accuracy: 0.8701\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5106 - accuracy: 0.8681 - val_loss: 0.4860 - val_accuracy: 0.8747\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4931 - accuracy: 0.8717 - val_loss: 0.4692 - val_accuracy: 0.8768\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4777 - accuracy: 0.8741 - val_loss: 0.4548 - val_accuracy: 0.8797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ffjzr8hQKb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e7822c-47fb-43f6-e8ab-1ab663e59e35"
      },
      "source": [
        "score = model_sigmoid.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.45478373765945435\n",
            "Test accuracy: 0.8797000050544739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExLv_CAeQKcA"
      },
      "source": [
        "<h2>MLP + Sigmoid activation + ADAM </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9BtnNGaQKcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9afb4227-e048-415f-e605-7749a8171c9e"
      },
      "source": [
        "model_sigmoid = Sequential()\n",
        "model_sigmoid.add(Dense(512, activation='sigmoid', input_shape=(input_dim,)))\n",
        "model_sigmoid.add(Dense(128, activation='sigmoid'))\n",
        "model_sigmoid.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "model_sigmoid.summary()\n",
        "\n",
        "model_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_sigmoid.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 468,874\n",
            "Trainable params: 468,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.5358 - accuracy: 0.8588 - val_loss: 0.2478 - val_accuracy: 0.9260\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2182 - accuracy: 0.9352 - val_loss: 0.1781 - val_accuracy: 0.9477\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1599 - accuracy: 0.9530 - val_loss: 0.1389 - val_accuracy: 0.9592\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1230 - accuracy: 0.9630 - val_loss: 0.1144 - val_accuracy: 0.9642\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0964 - accuracy: 0.9715 - val_loss: 0.0996 - val_accuracy: 0.9688\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0775 - accuracy: 0.9769 - val_loss: 0.0894 - val_accuracy: 0.9722\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0619 - accuracy: 0.9816 - val_loss: 0.0760 - val_accuracy: 0.9759\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0505 - accuracy: 0.9852 - val_loss: 0.0818 - val_accuracy: 0.9747\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0408 - accuracy: 0.9880 - val_loss: 0.0706 - val_accuracy: 0.9776\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0329 - accuracy: 0.9908 - val_loss: 0.0685 - val_accuracy: 0.9788\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.0644 - val_accuracy: 0.9798\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.9944 - val_loss: 0.0589 - val_accuracy: 0.9824\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 0.0583 - val_accuracy: 0.9822\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0628 - val_accuracy: 0.9814\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.0656 - val_accuracy: 0.9809\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.0627 - val_accuracy: 0.9817\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0687 - val_accuracy: 0.9800\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0695 - val_accuracy: 0.9816\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0674 - val_accuracy: 0.9812\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0836 - val_accuracy: 0.9791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AslSnqQ2QKcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d64550f-4e1e-4b6f-d73a-5975fd7419f2"
      },
      "source": [
        "score = model_sigmoid.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.08360856771469116\n",
            "Test accuracy: 0.9790999889373779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRVrzqvSQKcL"
      },
      "source": [
        "<h2> MLP + ReLU +SGD </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8lG2jzmQKcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee5a228-4567-460d-8720-3aaf3b099777"
      },
      "source": [
        "# Multilayer perceptron\n",
        "model_relu = Sequential()\n",
        "model_relu.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
        "model_relu.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
        "model_relu.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "model_relu.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 468,874\n",
            "Trainable params: 468,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhtoviFKQKcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a2868b-1fdb-4083-a7c1-18bc614148f1"
      },
      "source": [
        "model_relu.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_relu.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.7756 - accuracy: 0.7861 - val_loss: 0.3946 - val_accuracy: 0.8934\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3607 - accuracy: 0.8990 - val_loss: 0.3065 - val_accuracy: 0.9150\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.9146 - val_loss: 0.2674 - val_accuracy: 0.9239\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.9247 - val_loss: 0.2438 - val_accuracy: 0.9293\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.2411 - accuracy: 0.9316 - val_loss: 0.2273 - val_accuracy: 0.9343\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2225 - accuracy: 0.9366 - val_loss: 0.2092 - val_accuracy: 0.9373\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2069 - accuracy: 0.9416 - val_loss: 0.1978 - val_accuracy: 0.9412\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9452 - val_loss: 0.1895 - val_accuracy: 0.9438\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1832 - accuracy: 0.9480 - val_loss: 0.1801 - val_accuracy: 0.9460\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1734 - accuracy: 0.9511 - val_loss: 0.1714 - val_accuracy: 0.9489\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1645 - accuracy: 0.9538 - val_loss: 0.1641 - val_accuracy: 0.9516\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1567 - accuracy: 0.9558 - val_loss: 0.1595 - val_accuracy: 0.9524\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1496 - accuracy: 0.9580 - val_loss: 0.1535 - val_accuracy: 0.9533\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9595 - val_loss: 0.1508 - val_accuracy: 0.9559\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1370 - accuracy: 0.9609 - val_loss: 0.1436 - val_accuracy: 0.9563\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1315 - accuracy: 0.9632 - val_loss: 0.1392 - val_accuracy: 0.9571\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1263 - accuracy: 0.9646 - val_loss: 0.1350 - val_accuracy: 0.9583\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1216 - accuracy: 0.9656 - val_loss: 0.1313 - val_accuracy: 0.9608\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1171 - accuracy: 0.9672 - val_loss: 0.1313 - val_accuracy: 0.9594\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.1131 - accuracy: 0.9686 - val_loss: 0.1271 - val_accuracy: 0.9611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rKzoKxgQKcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee743865-36e2-442d-fbe9-15822a82888a"
      },
      "source": [
        "score = model_relu.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.12711843848228455\n",
            "Test accuracy: 0.9610999822616577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ccmfiVGQKcc"
      },
      "source": [
        "<h2> MLP + ReLU + ADAM </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CtwrinkQKcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c0fad13-d927-4526-d22e-29952c8e3ff7"
      },
      "source": [
        "model_relu = Sequential()\n",
        "model_relu.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
        "model_relu.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
        "model_relu.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "print(model_relu.summary())\n",
        "\n",
        "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_relu.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 468,874\n",
            "Trainable params: 468,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2251 - accuracy: 0.9334 - val_loss: 0.1122 - val_accuracy: 0.9665\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0864 - accuracy: 0.9742 - val_loss: 0.0936 - val_accuracy: 0.9696\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0538 - accuracy: 0.9838 - val_loss: 0.0764 - val_accuracy: 0.9771\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0362 - accuracy: 0.9891 - val_loss: 0.0734 - val_accuracy: 0.9766\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0728 - val_accuracy: 0.9779\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0886 - val_accuracy: 0.9748\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0993 - val_accuracy: 0.9723\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0740 - val_accuracy: 0.9820\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0811 - val_accuracy: 0.9804\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.0851 - val_accuracy: 0.9793\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0772 - val_accuracy: 0.9803\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1014 - val_accuracy: 0.9779\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0849 - val_accuracy: 0.9803\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1012 - val_accuracy: 0.9786\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0998 - val_accuracy: 0.9768\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0897 - val_accuracy: 0.9803\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1033 - val_accuracy: 0.9792\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0893 - val_accuracy: 0.9817\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0974 - val_accuracy: 0.9785\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0983 - val_accuracy: 0.9804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niCdh2TUQKce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599b398f-f1c4-4986-c0cb-8c54f7da4355"
      },
      "source": [
        "score = model_relu.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.0982968658208847\n",
            "Test accuracy: 0.980400025844574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjduBU7hQKch"
      },
      "source": [
        "<h2> MLP + Batch-Norm on hidden Layers + AdamOptimizer </2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGHnPnoTQKci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68b6031-b956-40e4-e80c-e78884414e84"
      },
      "source": [
        "# Multilayer perceptron\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "model_batch = Sequential()\n",
        "\n",
        "model_batch.add(Dense(512, activation='sigmoid', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
        "model_batch.add(BatchNormalization())\n",
        "\n",
        "model_batch.add(Dense(128, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
        "model_batch.add(BatchNormalization())\n",
        "\n",
        "model_batch.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "\n",
        "model_batch.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_13 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 471,434\n",
            "Trainable params: 470,154\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMPo5fcUQKcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8e66ec-7bbd-47da-e3d5-ef57c2bfe02b"
      },
      "source": [
        "model_batch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_batch.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 4s 5ms/step - loss: 0.3044 - accuracy: 0.9104 - val_loss: 0.2014 - val_accuracy: 0.9426\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1756 - accuracy: 0.9484 - val_loss: 0.1728 - val_accuracy: 0.9490\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1385 - accuracy: 0.9593 - val_loss: 0.1529 - val_accuracy: 0.9569\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1151 - accuracy: 0.9652 - val_loss: 0.1370 - val_accuracy: 0.9591\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0966 - accuracy: 0.9699 - val_loss: 0.1340 - val_accuracy: 0.9582\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0834 - accuracy: 0.9742 - val_loss: 0.1275 - val_accuracy: 0.9617\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0712 - accuracy: 0.9779 - val_loss: 0.1140 - val_accuracy: 0.9646\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.1160 - val_accuracy: 0.9638\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0534 - accuracy: 0.9834 - val_loss: 0.1092 - val_accuracy: 0.9675\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0485 - accuracy: 0.9841 - val_loss: 0.1061 - val_accuracy: 0.9686\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.1037 - val_accuracy: 0.9697\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 0.1134 - val_accuracy: 0.9671\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.1028 - val_accuracy: 0.9695\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.1012 - val_accuracy: 0.9691\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0965 - val_accuracy: 0.9727\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.1050 - val_accuracy: 0.9706\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.1147 - val_accuracy: 0.9686\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.1062 - val_accuracy: 0.9720\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.1114 - val_accuracy: 0.9692\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.1057 - val_accuracy: 0.9744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HThyBcHUQKcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7260c966-06f7-4041-c8b6-6164a362e0d8"
      },
      "source": [
        "score = model_batch.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.10566598176956177\n",
            "Test accuracy: 0.974399983882904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> 5. MLP + BatchNormalisation on hiddenlayer + AdamOptimizer + Relu"
      ],
      "metadata": {
        "id": "W35Og7ObRBxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer perceptron\n",
        "model_relu_batch = Sequential()\n",
        "model_relu_batch.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
        "model_relu_batch.add(BatchNormalization())\n",
        "\n",
        "model_relu_batch.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
        "model_relu_batch.add(BatchNormalization())\n",
        "\n",
        "model_relu_batch.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "model_relu_batch.summary()"
      ],
      "metadata": {
        "id": "Mie5YL5XQY9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdeee7ba-c646-4963-b9f0-e6802dfa28b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_16 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 471,434\n",
            "Trainable params: 470,154\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu_batch.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_relu_batch.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjLLouFzQYzd",
        "outputId": "af383fa0-ae79-4f67-d423-e38b36241cb8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.2037 - accuracy: 0.9388 - val_loss: 0.1042 - val_accuracy: 0.9696\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0695 - accuracy: 0.9797 - val_loss: 0.0792 - val_accuracy: 0.9738\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0429 - accuracy: 0.9871 - val_loss: 0.0851 - val_accuracy: 0.9745\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0304 - accuracy: 0.9907 - val_loss: 0.0858 - val_accuracy: 0.9742\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0235 - accuracy: 0.9929 - val_loss: 0.0810 - val_accuracy: 0.9743\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.0744 - val_accuracy: 0.9782\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0754 - val_accuracy: 0.9774\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0762 - val_accuracy: 0.9792\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0881 - val_accuracy: 0.9777\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.0948 - val_accuracy: 0.9751\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0720 - val_accuracy: 0.9818\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0820 - val_accuracy: 0.9782\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0698 - val_accuracy: 0.9811\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0921 - val_accuracy: 0.9796\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0791 - val_accuracy: 0.9812\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0774 - val_accuracy: 0.9814\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0857 - val_accuracy: 0.9789\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0802 - val_accuracy: 0.9807\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0786 - val_accuracy: 0.9805\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0914 - val_accuracy: 0.9792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model_relu_batch.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "kMxnlzI5QYqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fac7bb-50e9-469b-eeb9-e189dfb98c2d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.0913720577955246\n",
            "Test accuracy: 0.979200005531311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. MLP + BatchNormalisation on hiddenlayer + Dropout  + AdamOptimizer + Relu"
      ],
      "metadata": {
        "id": "mqW7g-rlRvsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer perceptron\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model_relu_drop = Sequential()\n",
        "model_relu_drop.add(Dense(512, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
        "model_relu_drop.add(BatchNormalization())\n",
        "model_relu_drop.add(Dropout(0.5))\n",
        "\n",
        "model_relu_drop.add(Dense(128, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
        "model_relu_drop.add(BatchNormalization())\n",
        "model_relu_drop.add(Dropout(0.5))\n",
        "\n",
        "model_relu_drop.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "model_relu_drop.summary()"
      ],
      "metadata": {
        "id": "knKsFHa3R7kO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751e26eb-bd9b-4b56-b77d-106ff1b34476"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 471,434\n",
            "Trainable params: 470,154\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu_drop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_relu_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "metadata": {
        "id": "vgYXIERSR7bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca78734-04a7-4220-a69c-43ac2b5f2303"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.4959 - accuracy: 0.8493 - val_loss: 0.1567 - val_accuracy: 0.9529\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2264 - accuracy: 0.9323 - val_loss: 0.1209 - val_accuracy: 0.9625\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1788 - accuracy: 0.9466 - val_loss: 0.0967 - val_accuracy: 0.9690\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1511 - accuracy: 0.9543 - val_loss: 0.0846 - val_accuracy: 0.9727\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1316 - accuracy: 0.9599 - val_loss: 0.0790 - val_accuracy: 0.9748\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1175 - accuracy: 0.9649 - val_loss: 0.0735 - val_accuracy: 0.9763\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1070 - accuracy: 0.9674 - val_loss: 0.0710 - val_accuracy: 0.9782\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0969 - accuracy: 0.9693 - val_loss: 0.0696 - val_accuracy: 0.9793\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0925 - accuracy: 0.9716 - val_loss: 0.0670 - val_accuracy: 0.9793\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0878 - accuracy: 0.9728 - val_loss: 0.0692 - val_accuracy: 0.9790\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0820 - accuracy: 0.9743 - val_loss: 0.0630 - val_accuracy: 0.9814\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0764 - accuracy: 0.9766 - val_loss: 0.0590 - val_accuracy: 0.9816\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0714 - accuracy: 0.9776 - val_loss: 0.0573 - val_accuracy: 0.9820\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0701 - accuracy: 0.9776 - val_loss: 0.0574 - val_accuracy: 0.9825\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0643 - accuracy: 0.9796 - val_loss: 0.0602 - val_accuracy: 0.9830\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0616 - accuracy: 0.9805 - val_loss: 0.0618 - val_accuracy: 0.9811\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0622 - accuracy: 0.9804 - val_loss: 0.0585 - val_accuracy: 0.9832\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0594 - accuracy: 0.9816 - val_loss: 0.0518 - val_accuracy: 0.9854\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0559 - accuracy: 0.9825 - val_loss: 0.0577 - val_accuracy: 0.9824\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0537 - accuracy: 0.9826 - val_loss: 0.0582 - val_accuracy: 0.9834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model_relu_drop.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "id": "Cxfjzcb3R7Tj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e4bd96-1d52-4979-c0da-0a524a4dbb6d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.05815555527806282\n",
            "Test accuracy: 0.9833999872207642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWYP8-3pQKct"
      },
      "source": [
        "<h2> 7. MLP + Dropout + AdamOptimizer </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJj0hu0-QKct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475662ff-d80c-42b7-bc9d-8fb7d09461cf"
      },
      "source": [
        "# https://stackoverflow.com/questions/34716454/where-do-i-call-the-batchnormalization-function-in-keras\n",
        "\n",
        "\n",
        "model_drop = Sequential()\n",
        "\n",
        "model_drop.add(Dense(512, activation='sigmoid', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
        "model_drop.add(BatchNormalization())\n",
        "model_drop.add(Dropout(0.5))\n",
        "\n",
        "model_drop.add(Dense(128, activation='sigmoid', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
        "model_drop.add(BatchNormalization())\n",
        "model_drop.add(Dropout(0.5))\n",
        "\n",
        "model_drop.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "\n",
        "model_drop.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 471,434\n",
            "Trainable params: 470,154\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5pc4W_9QKcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1c66fc-5300-433b-92f9-f16318d2242a"
      },
      "source": [
        "model_drop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.6712 - accuracy: 0.7928 - val_loss: 0.2896 - val_accuracy: 0.9157\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4319 - accuracy: 0.8677 - val_loss: 0.2586 - val_accuracy: 0.9254\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3842 - accuracy: 0.8847 - val_loss: 0.2412 - val_accuracy: 0.9277\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3598 - accuracy: 0.8908 - val_loss: 0.2221 - val_accuracy: 0.9334\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3389 - accuracy: 0.8970 - val_loss: 0.2123 - val_accuracy: 0.9360\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3209 - accuracy: 0.9037 - val_loss: 0.2069 - val_accuracy: 0.9376\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3114 - accuracy: 0.9057 - val_loss: 0.1975 - val_accuracy: 0.9413\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2970 - accuracy: 0.9095 - val_loss: 0.1851 - val_accuracy: 0.9443\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2864 - accuracy: 0.9141 - val_loss: 0.1788 - val_accuracy: 0.9450\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2673 - accuracy: 0.9206 - val_loss: 0.1712 - val_accuracy: 0.9498\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2589 - accuracy: 0.9218 - val_loss: 0.1620 - val_accuracy: 0.9519\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2489 - accuracy: 0.9248 - val_loss: 0.1555 - val_accuracy: 0.9515\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2371 - accuracy: 0.9290 - val_loss: 0.1442 - val_accuracy: 0.9559\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2236 - accuracy: 0.9332 - val_loss: 0.1385 - val_accuracy: 0.9583\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2130 - accuracy: 0.9361 - val_loss: 0.1319 - val_accuracy: 0.9605\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.2031 - accuracy: 0.9388 - val_loss: 0.1238 - val_accuracy: 0.9642\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1990 - accuracy: 0.9410 - val_loss: 0.1164 - val_accuracy: 0.9648\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1865 - accuracy: 0.9437 - val_loss: 0.1145 - val_accuracy: 0.9666\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1806 - accuracy: 0.9466 - val_loss: 0.1107 - val_accuracy: 0.9665\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1781 - accuracy: 0.9458 - val_loss: 0.1089 - val_accuracy: 0.9687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5WcfQRFQKc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed6ca85-6141-442f-9fc7-52dea774d5e4"
      },
      "source": [
        "score = model_drop.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score: 0.10891246050596237\n",
            "Test accuracy: 0.9686999917030334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayBTjaZGQKc6"
      },
      "source": [
        "<h2> Hyper-parameter tuning of Keras models using Sklearn </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k1L9fZcQKc6"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n",
        "def best_hyperparameters(activ):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation=activ, input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
        "    model.add(Dense(128, activation=activ, kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
        "    model.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj1klnwWQKc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4cfdcd-22f7-4cb2-cda1-a04efde07808"
      },
      "source": [
        "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
        "\n",
        "\n",
        "activ = ['sigmoid','relu']\n",
        "\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = KerasClassifier(build_fn=best_hyperparameters, epochs=nb_epoch, batch_size=batch_size, verbose=0)\n",
        "param_grid = dict(activ=activ)\n",
        "\n",
        "# if you are using CPU\n",
        "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
        "# if you are using GPU dont use the n_jobs parameter\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, Y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UiW9qkmQKc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfca4eee-2ef9-4cba-9767-14e2139c046e"
      },
      "source": [
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.977650 using {'activ': 'sigmoid'}\n",
            "0.977650 (0.001724) with: {'activ': 'sigmoid'}\n",
            "0.977283 (0.003423) with: {'activ': 'relu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable    \n",
        "y = PrettyTable()\n",
        "y.field_names = [ \"Activation \",  \"Optimser\",\"BatNormalisation\",\"Dropoutrate\" ,\"test_accuracy\"]\n",
        "\n",
        "y.add_row([\"Softmax\", \"sgd\",  \"No\" , \"No\" ,  0.9099])   \n",
        "y.add_row([\"2 Sigmoid + Softmax \",\" sgd\",\" NO\", \" No\", 0.8797]) \n",
        "y.add_row([\"2 Sigmoid + Softmax \",\" adam\", \"NO\", \" No\", 0.979]) \n",
        "y.add_row([\"2 relu + Softmax \",\" sgd\",\"NO\", \" No\", 0.961]) \n",
        "y.add_row([\"2 relu + Softmax \",\" adam\",\"NO\", \" No\", 0.9804]) \n",
        "\n",
        "y.add_row([\"2 sigmod + Softmax \",  \" adam\", \" YES\", \" No\", 0.973]) \n",
        "y.add_row([\"2 sigmod + Softmax \",  \" adam\", \" YES\", \" YES\", 0.968]) \n",
        "y.add_row([\"2 relu + Softmax \",  \" adam\", \" YES\", \" No\",  0.979]) \n",
        "y.add_row([\"2 relu + Softmax \",  \" adam\", \" YES\", \" YES\",  0.983]) \n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cRoaX1GLOXx",
        "outputId": "d2ce744c-2923-4956-d805-b52335610e99"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+----------+------------------+-------------+---------------+\n",
            "|     Activation       | Optimser | BatNormalisation | Dropoutrate | test_accuracy |\n",
            "+----------------------+----------+------------------+-------------+---------------+\n",
            "|       Softmax        |   sgd    |        No        |      No     |     0.9099    |\n",
            "| 2 Sigmoid + Softmax  |    sgd   |        NO        |      No     |     0.8797    |\n",
            "| 2 Sigmoid + Softmax  |   adam   |        NO        |      No     |     0.979     |\n",
            "|  2 relu + Softmax    |    sgd   |        NO        |      No     |     0.961     |\n",
            "|  2 relu + Softmax    |   adam   |        NO        |      No     |     0.9804    |\n",
            "| 2 sigmod + Softmax   |   adam   |        YES       |      No     |     0.973     |\n",
            "| 2 sigmod + Softmax   |   adam   |        YES       |      YES    |     0.968     |\n",
            "|  2 relu + Softmax    |   adam   |        YES       |      No     |     0.979     |\n",
            "|  2 relu + Softmax    |   adam   |        YES       |      YES    |     0.983     |\n",
            "+----------------------+----------+------------------+-------------+---------------+\n"
          ]
        }
      ]
    }
  ]
}